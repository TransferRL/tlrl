{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "n_samples = 10000\n",
    "\n",
    "n_input = 10\n",
    "n_output = 5\n",
    "n_hidden = 15\n",
    "n_layers = 2\n",
    "hidden_dict = {}\n",
    "\n",
    "opt = tf.train.MomentumOptimizer(\n",
    "    learning_rate=0.0000000001,\n",
    "    momentum=0.7)\n",
    "\n",
    "discount = 0.5\n",
    "\n",
    "# TODO USE ACTUAL MAPPED INSTANCES INSTEAD OF THESE RANDOMLY GENERATED VECTORS\n",
    "actions = np.random.binomial(n_output-1,[1/n_output],n_samples)\n",
    "instances = np.arange(n_input*n_samples).reshape(n_samples,n_input).astype(float)\n",
    "transitions = np.arange(n_input*n_samples).reshape(n_samples,n_input).astype(float)\n",
    "rewards = np.matmul(0.0001*np.arange(n_input).reshape(1,-1),instances.T) ** 2 \n",
    "\n",
    "\n",
    "# TODO STANDARDIZE INPUTS AND OUTPUTS\n",
    "\n",
    "ini_mean = 0\n",
    "ini_std = 1\n",
    "activation = tf.nn.relu\n",
    "\n",
    "def weight_matrix(n_from,n_to):\n",
    "    return tf.Variable(tf.truncated_normal(\n",
    "        shape=(n_from,n_to)\n",
    "        ,mean=ini_mean\n",
    "        ,stddev=ini_std/np.sqrt(n_from+n_to)\n",
    "        ,dtype=tf.float32))\n",
    "\n",
    "def bias_matrix(n_to):\n",
    "    return tf.Variable(tf.zeros(shape=(1,n_to),dtype=tf.float32))\n",
    "\n",
    "\n",
    "input_layer = tf.placeholder(name='q_input', shape=(None,n_input),dtype=tf.float32)\n",
    "\n",
    "for n in range(1,n_layers+1):\n",
    "    hidden_dict[n] = {}\n",
    "    if n == 1:\n",
    "        hidden_dict[n]['weights'] = weight_matrix(n_input,n_hidden)\n",
    "        hidden_dict[n]['bias'] = bias_matrix(n_hidden)\n",
    "        hidden_dict[n]['layer'] = activation(tf.matmul(input_layer,hidden_dict[n]['weights']) + hidden_dict[n]['bias'])\n",
    "    else:\n",
    "        hidden_dict[n]['weights'] = weight_matrix(n_hidden,n_hidden)\n",
    "        hidden_dict[n]['bias'] = bias_matrix(n_hidden)\n",
    "        hidden_dict[n]['layer'] = activation(tf.matmul(hidden_dict[n-1]['layer'],hidden_dict[n]['weights']) + hidden_dict[n]['bias'])\n",
    "        \n",
    "\n",
    "output_weights = weight_matrix(n_hidden,n_output)\n",
    "output_bias = bias_matrix(n_output)\n",
    "\n",
    "output_pred = tf.matmul(hidden_dict[n_layers]['layer'],output_weights) + output_bias\n",
    "output_truth = tf.placeholder(shape=(None,n_output),dtype=tf.float32)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.l2_loss(output_truth - output_pred))\n",
    "\n",
    "\n",
    "all_variables = [hidden_dict[n]['weights'] for n in range(1,n_layers+1)] + [output_weights] + [hidden_dict[n]['bias'] for n in range(1,n_layers+1)] + [output_bias]\n",
    "opt_op = opt.minimize(loss, var_list = all_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      "loss: nan:   0%|          | 5/5000 [00:00<01:40, 49.68it/s]\u001b[A\n",
      "loss: nan:   0%|          | 11/5000 [00:00<01:36, 51.71it/s]\u001b[A\n",
      "loss: nan:   0%|          | 17/5000 [00:00<01:33, 53.58it/s]\u001b[A\n",
      "loss: nan:   0%|          | 24/5000 [00:00<01:29, 55.54it/s]\u001b[A\n",
      "loss: nan:   1%|          | 29/5000 [00:00<01:36, 51.41it/s]\u001b[A\n",
      "loss: nan:   1%|          | 34/5000 [00:00<01:43, 48.01it/s]\u001b[A\n",
      "loss: nan:   1%|          | 39/5000 [00:00<01:55, 43.05it/s]\u001b[A\n",
      "loss: nan:   1%|          | 44/5000 [00:00<01:59, 41.40it/s]\u001b[A\n",
      "loss: nan:   1%|          | 48/5000 [00:01<02:06, 39.04it/s]\u001b[A\n",
      "loss: nan:   1%|          | 53/5000 [00:01<02:02, 40.43it/s]\u001b[A\n",
      "loss: nan:   1%|          | 58/5000 [00:01<02:00, 40.89it/s]\u001b[A\n",
      "loss: nan:   1%|▏         | 63/5000 [00:01<02:01, 40.48it/s]\u001b[A\n",
      "loss: nan:   1%|▏         | 68/5000 [00:01<01:57, 42.01it/s]\u001b[A\n",
      "loss: nan:   1%|▏         | 73/5000 [00:01<01:51, 44.05it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 79/5000 [00:01<01:44, 47.07it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 85/5000 [00:01<01:41, 48.20it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 90/5000 [00:01<01:45, 46.70it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 95/5000 [00:02<01:54, 42.70it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 100/5000 [00:02<02:01, 40.37it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 105/5000 [00:02<01:58, 41.21it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 110/5000 [00:02<01:52, 43.34it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 115/5000 [00:02<01:49, 44.80it/s]\u001b[A\n",
      "loss: nan:   2%|▏         | 121/5000 [00:02<01:41, 48.19it/s]\u001b[A\n",
      "loss: nan:   3%|▎         | 126/5000 [00:02<01:48, 44.91it/s]\u001b[A\n",
      "loss: nan:   3%|▎         | 131/5000 [00:02<02:02, 39.85it/s]\u001b[A\n",
      "loss: nan:   3%|▎         | 136/5000 [00:03<02:14, 36.13it/s]\u001b[A\n",
      "loss: nan:   3%|▎         | 140/5000 [00:03<02:22, 34.18it/s]\u001b[A\n",
      "loss: nan:   3%|▎         | 144/5000 [00:03<02:22, 33.96it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9b9612c424aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mground_truth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbellman_trans_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_truth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0m_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(\"./tmp/model.ckpt\")\n",
    "\n",
    "n_epochs = 5000\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "pbar = tqdm(range(n_epochs))\n",
    "_losses = []\n",
    "for _ in pbar:\n",
    "\n",
    "    bellman_trans_q = np.max(sess.run(output_pred, feed_dict={input_layer:transitions}),axis=1)\n",
    "\n",
    "    ground_truth = sess.run(output_pred, feed_dict={input_layer:instances})\n",
    "    ground_truth[list(range(n_samples)),actions] = rewards + discount*bellman_trans_q\n",
    "\n",
    "    _, _loss = sess.run([opt_op,loss],feed_dict={input_layer:instances, output_truth:ground_truth})\n",
    "    _losses.append(_loss)\n",
    "    pbar.set_description('loss: {}'.format(_loss))\n",
    "    \n",
    "    ### TODO : Save model w/trained variables for use in target task\n",
    "    \n",
    "builder.add_meta_graph_and_variables(sess,\n",
    "                                     ['q_learning']\n",
    "                                        \n",
    "                                       )\n",
    "\n",
    "save_path = builder.save()\n",
    "\n",
    "print('done - model saved at', save_path)\n",
    "\n",
    "sess.close()\n",
    "    \n",
    "plt.plot(list(range(n_epochs)),_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   168.65229797,    169.65229797,    170.65229797, ...,\n",
       "        10165.65229797,  10166.65229797,  10167.65229797])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards + discount*bellman_trans_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00155675,  0.00486267,  0.00815904,  0.01144711,  0.01473459,\n",
       "        0.01802206,  0.02130952,  0.024597  ,  0.02788446,  0.03117194,\n",
       "        0.03445941,  0.03774688,  0.04103435,  0.04432182,  0.04760929,\n",
       "        0.05089676,  0.05418424,  0.0574717 ,  0.06075917,  0.06404664,\n",
       "        0.06733412,  0.07062159,  0.07390906,  0.07719652,  0.080484  ,\n",
       "        0.08377147,  0.08705894,  0.0903464 ,  0.09363387,  0.09692135,\n",
       "        0.10020883,  0.1034963 ,  0.10678376,  0.11007124,  0.11335869,\n",
       "        0.11664617,  0.11993365,  0.12322111,  0.12650858,  0.12979603,\n",
       "        0.13308352,  0.136371  ,  0.13965845,  0.14294593,  0.14623341,\n",
       "        0.14952087,  0.15280832,  0.15609582,  0.15938328,  0.16267078,\n",
       "        0.16595821,  0.16924568,  0.17253317,  0.17582062,  0.17910813,\n",
       "        0.18239559,  0.18568304,  0.18897052,  0.192258  ,  0.19554541,\n",
       "        0.19883293,  0.20212041,  0.20540783,  0.20869534,  0.21198282,\n",
       "        0.21527027,  0.21855776,  0.22184522,  0.22513269,  0.22842018,\n",
       "        0.23170768,  0.23499513,  0.23828259,  0.24157003,  0.24485752,\n",
       "        0.24814501,  0.25143245,  0.25471991,  0.25800741,  0.26129484,\n",
       "        0.26458234,  0.2678698 ,  0.27115729,  0.27444476,  0.27773225,\n",
       "        0.28101969,  0.28430718,  0.28759465,  0.29088211,  0.29416952,\n",
       "        0.2974571 ,  0.3007445 ,  0.30403197,  0.30731946,  0.3106069 ,\n",
       "        0.31389439,  0.31718189,  0.32046935,  0.32375681,  0.32704428], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bellman_trans_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "d = deque([],5)\n",
    "\n",
    "d.append([np.array([1]),np.array([1]),np.array([1])])\n",
    "\n",
    "d.append([np.array([1]),np.array([1]),np.array([1])])\n",
    "\n",
    "d.append([np.array([1]),np.array([1]),np.array([1])])\n",
    "\n",
    "d.append([np.array([1]),np.array([1]),np.array([1])])\n",
    "\n",
    "d.append([np.array([1]),np.array([1]),np.array([1])])\n",
    "d.append([np.array([1]),np.array([1]),np.array([1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([1, 2, 3]),\n",
       "       array([1, 2, 3]),\n",
       "       array([1, 2, 3]),\n",
       "       array([1, 2, 3]),\n",
       "       array([1, 2, 3])])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "close() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-875dc22ffa3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: close() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "tf.Session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_vars = {\n",
    "                    \"momentum\":0.5}\n",
    "\n",
    "opt = tf.train.MomentumOptimizer(learning_rate=0.01,**opt_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(n_input*n_samples).reshape(n_samples,n_input).astype(float).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(1,[1/5],9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-7f8cf521bf21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice (numpy/random/mtrand/mtrand.c:17151)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "np.random.choice(np.array(d),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4\n"
     ]
    }
   ],
   "source": [
    "for a,b,c,d in zip([1],[2],[3],[4]):\n",
    "    print(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 519.845947265625:   0%|          | 2/500 [00:00<00:25, 19.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 527.7647705078125:   1%|          | 5/500 [00:00<00:22, 21.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 543.9395141601562:   2%|▏         | 8/500 [00:00<00:21, 22.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 559.4931030273438:   2%|▏         | 11/500 [00:00<00:20, 23.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 571.960693359375:   3%|▎         | 14/500 [00:00<00:19, 24.95it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 580.4751586914062:   3%|▎         | 17/500 [00:00<00:23, 20.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 583.245361328125:   4%|▍         | 19/500 [00:00<00:24, 19.90it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 579.2476806640625:   4%|▍         | 22/500 [00:00<00:23, 20.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 559.9461059570312:   5%|▌         | 25/500 [00:01<00:27, 17.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 530.5084228515625:   6%|▌         | 28/500 [00:01<00:27, 17.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 511.6873474121094:   6%|▌         | 30/500 [00:01<00:26, 17.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 495.66107177734375:   6%|▋         | 32/500 [00:01<00:26, 17.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 477.3502502441406:   7%|▋         | 35/500 [00:01<00:26, 17.41it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 468.45025634765625:   7%|▋         | 37/500 [00:01<00:25, 18.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 458.66668701171875:   8%|▊         | 40/500 [00:02<00:25, 18.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 453.84283447265625:   8%|▊         | 42/500 [00:02<00:24, 18.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 449.9359436035156:   9%|▉         | 44/500 [00:02<00:25, 18.05it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 445.3825988769531:   9%|▉         | 47/500 [00:02<00:23, 19.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 442.5373229980469:  10%|█         | 50/500 [00:02<00:22, 19.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 440.95623779296875:  11%|█         | 53/500 [00:02<00:22, 20.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 439.93402099609375:  11%|█         | 56/500 [00:02<00:21, 20.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 438.9711608886719:  12%|█▏        | 59/500 [00:02<00:21, 20.59it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 437.9842529296875:  12%|█▏        | 62/500 [00:03<00:21, 19.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 436.94415283203125:  13%|█▎        | 65/500 [00:03<00:21, 20.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 435.820068359375:  14%|█▎        | 68/500 [00:03<00:20, 21.45it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 434.6584167480469:  14%|█▍        | 71/500 [00:03<00:20, 20.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 433.4784240722656:  15%|█▍        | 74/500 [00:03<00:20, 20.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 432.285400390625:  15%|█▌        | 77/500 [00:03<00:20, 21.15it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 431.0712890625:  16%|█▌        | 80/500 [00:03<00:20, 20.93it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 429.85595703125:  17%|█▋        | 83/500 [00:04<00:20, 20.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 428.6657409667969:  17%|█▋        | 86/500 [00:04<00:20, 20.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 427.4938659667969:  18%|█▊        | 89/500 [00:04<00:19, 21.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 426.34344482421875:  18%|█▊        | 92/500 [00:04<00:18, 21.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 425.22222900390625:  19%|█▉        | 95/500 [00:04<00:18, 21.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 424.1290283203125:  20%|█▉        | 98/500 [00:04<00:19, 20.33it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 423.0555114746094:  20%|██        | 101/500 [00:04<00:19, 20.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 422.01171875:  21%|██        | 104/500 [00:05<00:19, 20.20it/s]     \u001b[A\u001b[A\n",
      "\n",
      "loss: 420.999267578125:  21%|██▏       | 107/500 [00:05<00:21, 18.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 420.01934814453125:  22%|██▏       | 110/500 [00:05<00:20, 19.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 419.06341552734375:  23%|██▎       | 113/500 [00:05<00:18, 21.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 418.1278076171875:  23%|██▎       | 116/500 [00:05<00:18, 20.30it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 417.2217712402344:  24%|██▍       | 119/500 [00:05<00:19, 20.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 416.3518981933594:  24%|██▍       | 122/500 [00:06<00:19, 19.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 415.78839111328125:  25%|██▍       | 124/500 [00:06<00:19, 19.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 415.23626708984375:  25%|██▌       | 126/500 [00:06<00:20, 18.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 414.69537353515625:  26%|██▌       | 128/500 [00:06<00:19, 18.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 413.90301513671875:  26%|██▌       | 131/500 [00:06<00:18, 20.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 413.1380615234375:  27%|██▋       | 134/500 [00:06<00:17, 21.07it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 412.40838623046875:  27%|██▋       | 137/500 [00:06<00:16, 22.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 411.70550537109375:  28%|██▊       | 140/500 [00:06<00:15, 22.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 411.0340881347656:  29%|██▊       | 143/500 [00:07<00:15, 22.84it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 410.3870849609375:  29%|██▉       | 146/500 [00:07<00:15, 22.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 409.76617431640625:  30%|██▉       | 149/500 [00:07<00:15, 23.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 409.17205810546875:  30%|███       | 152/500 [00:07<00:17, 20.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 408.59619140625:  31%|███       | 155/500 [00:07<00:16, 21.08it/s]   \u001b[A\u001b[A\n",
      "\n",
      "loss: 408.04205322265625:  32%|███▏      | 158/500 [00:07<00:16, 20.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 407.511962890625:  32%|███▏      | 161/500 [00:07<00:15, 22.15it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 406.996826171875:  33%|███▎      | 164/500 [00:08<00:16, 20.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 406.4989318847656:  33%|███▎      | 167/500 [00:08<00:17, 18.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 406.01953125:  34%|███▍      | 170/500 [00:08<00:16, 19.68it/s]     \u001b[A\u001b[A\n",
      "\n",
      "loss: 405.5547180175781:  35%|███▍      | 173/500 [00:08<00:16, 19.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 405.10870361328125:  35%|███▌      | 176/500 [00:08<00:16, 19.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 404.6783142089844:  36%|███▌      | 179/500 [00:08<00:14, 21.70it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 404.25830078125:  36%|███▋      | 182/500 [00:08<00:14, 22.17it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 403.85772705078125:  37%|███▋      | 185/500 [00:09<00:13, 23.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 403.46661376953125:  38%|███▊      | 188/500 [00:09<00:12, 24.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 402.96856689453125:  38%|███▊      | 192/500 [00:09<00:11, 25.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 402.607177734375:  39%|███▉      | 195/500 [00:09<00:11, 26.27it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 402.25531005859375:  40%|███▉      | 198/500 [00:09<00:11, 26.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 401.9134216308594:  40%|████      | 201/500 [00:09<00:11, 26.81it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 401.5793762207031:  41%|████      | 204/500 [00:09<00:11, 26.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 401.25701904296875:  41%|████▏     | 207/500 [00:09<00:11, 25.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 400.9515686035156:  42%|████▏     | 210/500 [00:09<00:11, 25.81it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 400.6576232910156:  43%|████▎     | 213/500 [00:10<00:10, 26.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 400.2822265625:  43%|████▎     | 217/500 [00:10<00:10, 27.66it/s]   \u001b[A\u001b[A\n",
      "\n",
      "loss: 400.0108337402344:  44%|████▍     | 220/500 [00:10<00:09, 28.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 399.6651916503906:  45%|████▍     | 224/500 [00:10<00:09, 28.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 399.3352966308594:  46%|████▌     | 228/500 [00:10<00:08, 30.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 399.0196228027344:  46%|████▋     | 232/500 [00:10<00:08, 29.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 398.7177429199219:  47%|████▋     | 236/500 [00:10<00:09, 28.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 398.49713134765625:  48%|████▊     | 239/500 [00:10<00:09, 27.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 398.21478271484375:  49%|████▊     | 243/500 [00:11<00:08, 28.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 398.0094909667969:  49%|████▉     | 246/500 [00:11<00:09, 28.02it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 397.8078308105469:  50%|████▉     | 249/500 [00:11<00:08, 28.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 397.5471496582031:  51%|█████     | 253/500 [00:11<00:09, 27.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 397.3580322265625:  51%|█████     | 256/500 [00:11<00:08, 27.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 397.1719055175781:  52%|█████▏    | 259/500 [00:11<00:08, 27.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 396.99200439453125:  52%|█████▏    | 262/500 [00:11<00:08, 27.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 396.75360107421875:  53%|█████▎    | 266/500 [00:11<00:08, 27.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 396.5253601074219:  54%|█████▍    | 270/500 [00:12<00:07, 28.98it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 396.3592529296875:  55%|█████▍    | 273/500 [00:12<00:07, 28.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 396.1964416503906:  55%|█████▌    | 276/500 [00:12<00:07, 28.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 395.9866943359375:  56%|█████▌    | 280/500 [00:12<00:07, 28.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 395.7789306640625:  57%|█████▋    | 284/500 [00:12<00:07, 29.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 395.61932373046875:  57%|█████▋    | 287/500 [00:12<00:07, 29.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 395.40545654296875:  58%|█████▊    | 291/500 [00:12<00:07, 29.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 395.2502136230469:  59%|█████▉    | 294/500 [00:12<00:06, 29.52it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 395.0450744628906:  60%|█████▉    | 298/500 [00:12<00:06, 29.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 394.8413391113281:  60%|██████    | 302/500 [00:13<00:06, 30.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 394.646240234375:  61%|██████    | 306/500 [00:13<00:06, 28.86it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 394.5062561035156:  62%|██████▏   | 309/500 [00:13<00:06, 28.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 394.3626708984375:  62%|██████▏   | 312/500 [00:13<00:06, 27.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 394.223876953125:  63%|██████▎   | 315/500 [00:13<00:06, 27.86it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 394.0903625488281:  64%|██████▎   | 318/500 [00:13<00:06, 27.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 393.96331787109375:  64%|██████▍   | 321/500 [00:13<00:06, 27.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 393.8355712890625:  65%|██████▍   | 324/500 [00:13<00:06, 27.54it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 393.7042236328125:  65%|██████▌   | 327/500 [00:14<00:06, 28.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 393.572021484375:  66%|██████▌   | 330/500 [00:14<00:06, 26.84it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 393.43975830078125:  67%|██████▋   | 333/500 [00:14<00:06, 27.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 393.271240234375:  67%|██████▋   | 337/500 [00:14<00:05, 27.88it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 393.1031799316406:  68%|██████▊   | 341/500 [00:14<00:05, 28.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 392.980224609375:  69%|██████▉   | 344/500 [00:14<00:05, 28.52it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 392.85882568359375:  69%|██████▉   | 347/500 [00:14<00:05, 25.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 392.7027587890625:  70%|███████   | 351/500 [00:14<00:05, 26.88it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 392.5854797363281:  71%|███████   | 354/500 [00:15<00:05, 26.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 392.4633483886719:  71%|███████▏  | 357/500 [00:15<00:05, 25.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 392.34112548828125:  72%|███████▏  | 360/500 [00:15<00:05, 26.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 392.22125244140625:  73%|███████▎  | 363/500 [00:15<00:05, 26.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 392.10601806640625:  73%|███████▎  | 366/500 [00:15<00:05, 25.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 391.99169921875:  74%|███████▍  | 369/500 [00:15<00:04, 26.51it/s]   \u001b[A\u001b[A\n",
      "\n",
      "loss: 391.876953125:  74%|███████▍  | 372/500 [00:15<00:04, 26.50it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 391.76666259765625:  75%|███████▌  | 375/500 [00:15<00:04, 26.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 391.6576843261719:  76%|███████▌  | 378/500 [00:15<00:04, 26.16it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 391.5455322265625:  76%|███████▌  | 381/500 [00:16<00:04, 26.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 391.3951416015625:  77%|███████▋  | 385/500 [00:16<00:04, 27.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 391.28009033203125:  78%|███████▊  | 388/500 [00:16<00:04, 26.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 391.163330078125:  78%|███████▊  | 391/500 [00:16<00:03, 27.56it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 391.04632568359375:  79%|███████▉  | 394/500 [00:16<00:03, 27.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 390.9290771484375:  79%|███████▉  | 397/500 [00:16<00:03, 27.91it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 390.779541015625:  80%|████████  | 401/500 [00:16<00:03, 28.60it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 390.6351318359375:  81%|████████  | 405/500 [00:16<00:03, 29.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 390.49029541015625:  82%|████████▏ | 409/500 [00:17<00:03, 29.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 390.37933349609375:  82%|████████▏ | 412/500 [00:17<00:03, 27.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 390.2703857421875:  83%|████████▎ | 415/500 [00:17<00:03, 26.06it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 390.1651306152344:  84%|████████▎ | 418/500 [00:17<00:03, 26.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 390.02001953125:  84%|████████▍ | 422/500 [00:17<00:02, 27.49it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 389.9058837890625:  85%|████████▌ | 425/500 [00:17<00:02, 27.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 389.7615966796875:  86%|████████▌ | 429/500 [00:17<00:02, 28.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 389.64971923828125:  86%|████████▋ | 432/500 [00:17<00:02, 27.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 389.5421447753906:  87%|████████▋ | 435/500 [00:17<00:02, 27.27it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 389.39599609375:  88%|████████▊ | 439/500 [00:18<00:02, 28.31it/s]  \u001b[A\u001b[A\n",
      "\n",
      "loss: 389.28790283203125:  88%|████████▊ | 442/500 [00:18<00:02, 28.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 389.1762390136719:  89%|████████▉ | 445/500 [00:18<00:01, 28.61it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 389.0672607421875:  90%|████████▉ | 448/500 [00:18<00:01, 27.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 388.9573669433594:  90%|█████████ | 451/500 [00:18<00:01, 28.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 388.84490966796875:  91%|█████████ | 454/500 [00:18<00:01, 27.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 388.7401428222656:  91%|█████████▏| 457/500 [00:18<00:01, 28.10it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 388.63336181640625:  92%|█████████▏| 460/500 [00:18<00:01, 26.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 388.52667236328125:  93%|█████████▎| 463/500 [00:19<00:01, 22.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 388.41741943359375:  93%|█████████▎| 466/500 [00:19<00:01, 24.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 388.31170654296875:  94%|█████████▍| 469/500 [00:19<00:01, 25.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 388.2010498046875:  94%|█████████▍| 472/500 [00:19<00:01, 26.43it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 388.0927429199219:  95%|█████████▌| 475/500 [00:19<00:00, 27.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 387.981689453125:  96%|█████████▌| 478/500 [00:19<00:00, 27.62it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 387.87127685546875:  96%|█████████▌| 481/500 [00:19<00:00, 28.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 387.76397705078125:  97%|█████████▋| 484/500 [00:19<00:00, 28.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 387.6561279296875:  97%|█████████▋| 487/500 [00:19<00:00, 28.17it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 387.54425048828125:  98%|█████████▊| 490/500 [00:19<00:00, 28.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 387.4280700683594:  99%|█████████▊| 493/500 [00:20<00:00, 28.82it/s] \u001b[A\u001b[A\n",
      "\n",
      "loss: 387.3127746582031:  99%|█████████▉| 496/500 [00:20<00:00, 28.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "loss: 387.1651306152344: 100%|██████████| 500/500 [00:20<00:00, 29.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhJyCnoRkZD7/0s0bepJh9ckAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c533208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run dqn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/dangoldberg/Desktop/code/tlrl/ammar_TrRBM/dqn.py\u001b[0m(103)\u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    101 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m            \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 103 \u001b[0;31m            \u001b[0mground_truth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoded_actions\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbellman_trans_q\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this is the bellman update for fitted q iteration, with all non-action outputs as the Q value that will be predicted by the current network - this negates any back-prop through these output nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    104 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    105 \u001b[0;31m            \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_truth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> coded_actions.shape\n",
      "(5000,)\n",
      "ipdb> len(states)\n",
      "5000\n",
      "ipdb> ground_truth.shape\n",
      "(5000, 5)\n",
      "ipdb> (rewards + (self.discount_rate * bellman_trans_q)).shape\n",
      "(5000, 5000)\n",
      "ipdb> rewards.shape\n",
      "(5000, 1)\n",
      "ipdb> (self.discount_rate * bellman_trans_q).shape\n",
      "(5000,)\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_new_obvs(states, actions, transitions, rewards):\n",
    "    for state, action, transition, reward in zip(states, actions, transitions, rewards):\n",
    "        memory.append([state, action, transition, reward])\n",
    "\n",
    "def get_memory_sample(size):\n",
    "    states, actions, transitions, rewards = [], [], [], []\n",
    "    for sample in self.memory:\n",
    "        states.append(sample[0])\n",
    "        actions.append(sample[1])\n",
    "        transitions.append(sample[2])\n",
    "        rewards.append(sample[3])\n",
    "\n",
    "    return states, actions, transitions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "d = collections.deque()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.43918282, -0.58444084,  0.11264756, ..., -0.4714663 ,\n",
       "          0.89249358, -0.55685438],\n",
       "        [-0.10888   , -1.14083787, -0.53595152, ...,  1.03122628,\n",
       "          0.65972543,  1.13463328],\n",
       "        [ 0.55203697, -0.31454331, -0.60457703, ..., -2.03158855,\n",
       "          0.26756465, -2.07458796],\n",
       "        ..., \n",
       "        [ 0.91891541, -1.49378155,  0.0181568 , ...,  0.81051976,\n",
       "          0.29324992,  1.61161804],\n",
       "        [-0.27262964,  0.1810991 , -1.21626747, ...,  0.38731252,\n",
       "          0.1738588 ,  2.16139519],\n",
       "        [-0.86596022,  0.33566534, -0.6122154 , ...,  2.30179071,\n",
       "         -0.69565123,  0.84795211]]),\n",
       " array([1, 0, 1, ..., 2, 1, 0]),\n",
       " array([[-0.19382411,  0.79656287, -2.94489154, ..., -0.65764776,\n",
       "          1.47483204,  1.66108011],\n",
       "        [-2.1695916 , -0.59184139,  0.11876494, ..., -1.29736823,\n",
       "          0.91997308, -0.02790676],\n",
       "        [-0.13390124,  0.96205925,  0.68200548, ..., -0.08187998,\n",
       "          1.51177828, -1.3507033 ],\n",
       "        ..., \n",
       "        [-0.32668367, -0.64985434, -1.6958892 , ...,  0.70060842,\n",
       "          0.52609761,  0.01983457],\n",
       "        [-0.83911219, -0.96104403,  0.59136387, ..., -0.01343143,\n",
       "          0.65207933, -0.7016137 ],\n",
       "        [-0.73816991, -1.54390135, -1.3755948 , ..., -1.16611198,\n",
       "         -1.25243886, -0.54744254]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states, actions, transitions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(states)):\n",
    "    d.append([states[i], actions[i], transitions[i], rewards[:,i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.36520282,  0.38565904,  0.44092397,  0.39307153,  0.99753586,\n",
       "         1.68507584,  0.2553062 ,  0.33435456,  0.31859158, -0.15276482]),\n",
       " 1,\n",
       " array([-0.24778851, -0.70925205, -0.4807787 ,  0.90672629, -1.84864831,\n",
       "         0.29696836, -1.31853372,  0.07155529, -0.04958519,  0.21237698]),\n",
       " array([0])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states, actions, transitions, rewards = [], [], [], []\n",
    "for sample in d:\n",
    "    states.append(sample[0])\n",
    "    actions.append(sample[1])\n",
    "    transitions.append(sample[2])\n",
    "    rewards.append(sample[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(states).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "a = collections.deque([],50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "while n < 10000:\n",
    "    n+=1\n",
    "    a.append([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([[1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       ...])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_memory_sample(deq, size):\n",
    "    states, actions, transitions, rewards = [], [], [], []\n",
    "    for i in np.random.choice(range(len(deq)),size):\n",
    "        states.append(deq[i][0])\n",
    "        actions.append(deq[i][1])\n",
    "        transitions.append(deq[i][2])\n",
    "        rewards.append(deq[i][3])\n",
    "        \n",
    "    return np.array(states), np.array(actions), np.array(transitions), np.array(rewards)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3]),\n",
       " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_sample(a, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
